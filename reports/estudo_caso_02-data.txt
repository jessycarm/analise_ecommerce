Relatório de Etapas de Limpeza de Dados

Etapa 0: Importação e Carregamento

    - Importamos as bibliotecas Pandas e NumPy, que serão utilizadas para o tratamento dos dados.
    - Carregamos o arquivo que será analisado.

Etapa 1: Verificação da Estrutura

    - Com df.shape, identificamos a quantidade de linhas e colunas: 541.909 linhas e 8 colunas.
    - Utilizamos df.head() para visualizar uma amostra da tabela.
       Exemplo da saída ([5 linhas x 8 colunas]): 
         InvoiceNo StockCode  ... CustomerID         Country
            0    536365    85123A  ...    17850.0  United Kingdom
            1    536365     71053  ...    17850.0  United Kingdom
            2    536365    84406B  ...    17850.0  United Kingdom
            3    536365    84029G  ...    17850.0  United Kingdom
            4    536365    84029E  ...    17850.0  United Kingdom

   - Verificação dos tipos de dados e valores não nulos:
        RangeIndex: 541909 entries, 0 to 541908
        Data columns (total 8 columns):
        #   Column       Non-Null Count   Dtype
        ---  ------       --------------   -----
        0   InvoiceNo    541909 non-null  object
        1   StockCode    541909 non-null  object
        2   Description  540455 non-null  object
        3   Quantity     541909 non-null  int64
        4   InvoiceDate  541909 non-null  object
        5   UnitPrice    541909 non-null  float64
        6   CustomerID   406829 non-null  float64
        7   Country      541909 non-null  object
        dtypes: float64(2), int64(1), object(5)
        memory usage: 33.1+ MB

        Resumo das colunas:

            - InvoiceNo: object → deveria ser string; se numérico, poderia estar em int.        
            - StockCode: object (correto, geralmente alfanumérico).
            - Description: object, contém valores nulos (1.454 ausências).
            - Quantity: int64, valores negativos indicam devoluções.
            - InvoiceDate: object, deveria ser datetime.
            - UnitPrice: float64, pode conter valores 0 ou negativos.
            - CustomerID: float64, deveria ser int64. Está como float devido a 135.080 ausências.
            - Country: object, deveria ser string categórica. 

        Dados faltantes (df.isnull().sum()):
            - Description → 1.454 valores ausentes.
            - CustomerID → 135.080 valores ausentes. 

Etapa 2: Correção dos Tipos de Dados

    - Conversão de InvoiceDate para datetime.
    - Conversão de CustomerID para int64.
    - Conversão de InvoiceNo e StockCode para string.
    - Conversão de Country para category (otimização de memória).
        Após ajustes:
        dtypes: Int64(1), category(1), datetime64 , float64(1), int64(1), object(3)  
        memory usage: 30.0+ MB

Etapa 3: Tratamento de Duplicatas

    - Identificação e remoção de duplicatas completas.
    - Duplicatas encontradas: 5.269 (0,97%).
    - Após a limpeza: 0 duplicatas.
    - Identificação de duplicatas parciais (InvoiceNo + StockCode): 5.415 registros.

Etapa 4: Tratamento de Devoluções/Cancelamentos

    - Quantidade negativa indica devolução.
    - Registros de devoluções: 10.587 → 19,73 por mil registros.

Etapa 5: Informações de Faturamento

    - Receita Total (com devoluções): R$ 9.726.003,05.
    - Receita Bruta (sem devoluções): R$ 10.619.982,78.
    - Impacto das devoluções: R$ 893.979,73.

Etapa 6: Padronização dos Dados

    - Remoção de espaços extras e uniformização de nomes.
    - Padronização de países (idiomas diferentes, abreviações, erros de digitação).
    - Frequência por país calculada.

        Exemplo:

        - United Kingdom → 490.299 registros (91,36%)
        - Germany → 9.480 registros (1,77%)
        - Brazil → 32 registros (0,01%)

Etapa 7: Tratamento de Preços e Outliers

    - Verificação de preços inválidos (zeros e negativos).
    - Detecção de outliers para avaliação antes de exclusão.
    - Outliers representam 7,35% dos dados.

Etapa 8: Criação de Colunas Temporais (Feature Engineering)

    Geração de variáveis derivadas de InvoiceDate: mês, dia da semana, sazonalidade.

Conclusão

    Após todas as etapas de limpeza, os dados foram:

    - Corrigidos quanto a tipos inconsistentes.
    - Padronizados e sem duplicatas.
    - Ajustados quanto a devoluções, outliers e preços inválidos.
    - Enriquecidos com variáveis temporais.
    - Os dados finais foram salvos para análise posterior.